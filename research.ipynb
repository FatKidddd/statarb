{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hurst import compute_Hc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "from sklearn.cluster import OPTICS\n",
    "from sklearn.decomposition import PCA\n",
    "from statsmodels.api import OLS\n",
    "import statsmodels.api as sm\n",
    "import datetime as dt\n",
    "\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# current idea now is cluster --> use johansen test to test for cointegration --> minimise portmanteau stat --> parametric threshold\n",
    "# or cluster --> engle granger test --> pairs with kalman filter --> parametric threshold\n",
    "\n",
    "etfs_dict = {\n",
    "\t# (1)\n",
    "\t'alternative': ['DALT'],\n",
    "\t# (219)\n",
    "\t'bonds': ['ADFI','AFIF','AGG','AGGY','AGZ','AGZD','ANGL','ARCM','AVIG','AWTM','BIV','BKAG','BKHY','BKSB','BLV','BND','BNDC','BSJL','BSJM','BSJN','BSJP','BSJQ','BSJR','BSJS','BSV','BTC','CEFS','CLTL','CMBS','CORP','DEED','DFHY','DIAL','DWFI','EDV','ESCR','ESHY','FALN','FCOR','FDHY','FFIU','FIGB','FISR','FLBL','FLCO','FLDR','FLGV','FLHY','FLOT','FLRN','FLRT','FLTB','FLTR','FSEC','FTSD','FTSL','FTSM','FWDB','GBF','GBIL','GCOR','GHYB','GHYG','GNMA','GOVT','GOVZ','GSIG','GSY','GTIP','GVI','HCRB','HOLD','HSRT','HTAB','HYBB','HYD','HYDB','HYDW','HYG','HYGH','HYGV','HYHG','HYIN','HYLB','HYLS','HYLV','HYMB','HYMU','HYS','HYTR','HYUP','HYXF','HYXU','HYZD','IBHA','IBHB','IBHC','IBHD','IBHE','ICSH','IEF','IEI','IG','IGBH','IGEB','IGHG','IGIB','IGLB','IGSB','IHY','IHYF','IIGD','IIGV','ILTB','ISTB','JAGG','JIGB','JMBS','JNK','JPHY','JPST','JSCP','KDFI','KORP','LDSF','LDUR','LGOV','LMBS','LQDH','LQDI','LSST','LTPZ','MBB','MBBB','MBSD','MIG','MINT','MTGP','NEAR','NFLT','NUAG','NUBD','NUHY','NUSA','OPER','OVT','PBND','PBTP','PHYL','PULS','QLTA','RAVI','RBND','RDFI','RINF','SCHI','SCHJ','SCHO','SCHP','SCHQ','SCHR','SCHZ','SHAG','SHV','SHY','SHYD','SHYG','SHYL','SJNK','SKOR','SLQD','SNLN','SPAB','SPBO','SPHY','SPIB','SPSB','SPTI','SPXB','SRLN','STIP','STPZ','SUSB','SUSC','TBJL','TDTF','TDTT','TFJL','TFLO','TFLT','TGIF','THY','TIP','TIPZ','TLH','TLT','ULTR','USFR','USHY','USI','USIG','USTB','VABS','VALT','VCIT','VCLT','VCSH','VGIT','VGLT','VGSH','VMBS','VNLA','VPC','VRP','VTC','VTIP','WBII','WINC','ZROZ'],\n",
    "\t# (18)\n",
    "\t'commodities_broad_basket': ['BCD','BCI','BCM','CCRV','COM','COMB','COMT','DBC','DJP','FTGC','GCC','GSG','GSP','JJS','JO','RJI','SDCI','UCIB'],\n",
    "\t# (10)\n",
    "\t'communications': ['EWCO','FCOM','FIVG','IWFH','IXP','IYZ','JHCS','VOX','XLC','XTL'],\n",
    "\t# (25)\n",
    "\t'consumer_discretionary': ['AWAY','BEDZ','BETZ','BJK','CARZ','EATZ','FDIS','FTXD','FXD','IBUY','ITB','IYC','NERD','ONLN','PBS','PEJ','PEZ','PSCD','RCD','RTH','RXI','VCR','XHB','XLY','XRT'],\n",
    "\t# (12)\n",
    "\t'consumer_staples': ['FSTA','FTXG','FXG','IECS','IYK','KXI','PBJ','PSCC','PSL','RHS','VDC','XLP'],\n",
    "\t# (11)\n",
    "\t'currencies': ['CEW','CYB','FXA','FXB','FXC','FXE','FXF','FXY','UDN','USDU','UUP'],\n",
    "\t# (14)\n",
    "\t'derivatives': ['CWB','DBMF','FCVT','FMF','FUT','ICVT','KMLM','MOM','OVB','OVF','OVL','OVM','OVS','WTMF'],\n",
    "\t# (169)\n",
    "\t'developed_markets': ['AFK','AGT','ARGT','AVMU','BBEU','BBJP','BDRY','BOTZ','BWX','BWZ','CMF','DAX','DBEU','DBEZ','DBGR','DBJP','DFE','DRIV','DUDE','DXGE','ECH','EDEN','EFNL','EGPT','EIDO','EIRL','EIS','ENOR','ENZL','EPHE','EPOL','EPU','ERTH','ERUS','EUCG','EUDG','EURZ','EWA','EWC','EWD','EWG','EWGS','EWI','EWJ','EWJE','EWJV','EWK','EWL','EWM','EWN','EWO','EWP','EWQ','EWS','EWU','EWUS','EWW','EWY','EZA','EZU','FAN','FCEF','FDD','FEUL','FEZ','FGM','FIEE','FKU','FLIA','FLMI','FMB','FNI','FPXE','FSZ','GAA','GMOM','GREK','GRID','GSEU','GSJY','GXF','GYLD','HEWG','HEWU','HEWW','HEZU','HJPX','HMOP','IBMO','IBND','ICLN','ICOL','IDX','IEUS','IEV','IGOV','INMU','ISHG','ISRA','ITM','IZRL','JETS','JMUB','JPN','JPXN','KWT','LDRS','MBND','MCEF','MCRO','MEAR','MINN','MJ','MJJ','MLN','MMIN','MMIT','MSOS','MUB','MUNI','MUST','NGE','NLR','NYF','OEUR','PAWZ','PBD','PBW','PEX','PGAL','PLAT','QCLN','QPX','RAAX','RIGS','RLY','ROMO','RSX','RSXJ','RTAI','RVNU','SCJ','SHM','SMB','SMEZ','SMMU','SMOG','SPEU','SUB','TAN','TAXF','TFIV','THCX','THD','TOKE','TRND','TUR','UAE','VGK','VICE','VNM','VOO','VTEB','WIP','XMPT','ZCAN','ZDEU','ZGBR','ZJPN'],\n",
    "\t# (142)\n",
    "\t'emerging_markets': ['AAXJ','ADIV','ADRE','AFTY','AIA','ASEA','ASHR','ASHS','BICK','BKEM','BKF','BRF','BSAE','BSBE','BSCE','BSDE','CBON','CEMB','CEY','CHB','CHIE','CHIH','CHII','CHIM','CHIQ','CHIS','CHIX','CN','CNXT','CQQQ','CXSE','DBEM','DGS','DMRE','DVYA','DVYE','EAPR','EBND','ECNS','ECON','ECOW','EDIV','EDOG','EELV','EEM','EEMA','EEMD','EEMO','EEMS','EEMX','EFIX','EJAN','ELD','EMAG','EMB','EMBD','EMBH','EMCB','EMDV','EMFM','EMGF','EMHC','EMHY','EMIF','EMLC','EMQQ','EMSG','EMSH','EMTL','EMXC','EPI','EPP','ESEB','EWEB','EWX','EWZ','EWZS','EYLD','FCA','FEM','FEMS','FLN','FLQE','FM','FNDE','FPA','GEM','GLCN','GLIN','GMF','GSEE','GXC','HAUZ','HYEM','IEMG','ILF','INCO','INDA','INDY','IPAC','ISEM','IXSE','JEMA','JHEM','JPEM','JPMB','KALL','KBA','KBUY','KEMQ','KEMX','KFVG','KFYP','KGRN','KMED','KSTR','KURE','KWEB','LEMB','MCHI','NFTY','PBEE','PGJ','PIE','PIN','PXH','QEMM','RESE','RFEM','RNEM','ROAM','SCHE','SMIN','SOVB','SPEM','TLTE','UEVM','VPL','VWO','VWOB','XCEM','ZHOK'],\n",
    "\t# (40)\n",
    "\t'energy': ['ACES','AMJ','AMLP','AMND','AMUB','AMZA','ATMP','BMLP','CNRG','CRAK','EINC','EMLP','ENFR','FCG','FENY','FILL','FRAK','FXN','IEO','IEZ','IMLP','IXC','IYE','MLPB','MLPO','MLPX','OIH','PSCE','PXE','PXI','PXJ','PYPE','RYE','TPYP','UMI','USAI','VDE','XES','XLE','XOP'],\n",
    "\t# (48)\n",
    "\t'equities': ['AOA','AOK','AOM','AOR','ASPY','CLIX','CVY','DBEH','DIVA','DWSH','DYHG','FDIV','FFSG','FLYT','FTLS','GAL','HIPS','HNDL','HTUS','INKM','IPFF','IYLD','MDIV','OCIO','PCEF','PFF','PFFA','PFFD','PFLD','PFXF','PGF','PGX','PHDG','PSK','PSMB','PSMC','PSMG','PSMM','PWS','QLS','QPT','RISN','RPAR','TACE','TEGS','USHG','VAMO','YLD'],\n",
    "\t# (630)\n",
    "\t'factors': ['ABEQ','ACSG','ACSI','ACTV','ACWX','AESR','AFLG','AFSM','AIEQ','ALTL','AMOM','ARKK','ARMR','AZAA','AZAJ','AZAL','AZAO','AZBA','AZBJ','AZBL','AZBO','BBIN','BBMC','BFOR','BIBL','BKIE','BKLC','BKMC','BKSE','BMAR','BMAY','BOB','BUFF','BUL','CACG','CALF','CAPE','CATH','CDL','CEFA','CFA','CFCV','CHGX','CID','CIL','CIZ','CLRG','COWZ','CSA','CSB','CSD','CSF','CSM','CSML','CWI','CWS','CZA','DALI','DBAW','DBEF','DBJA','DBLV','DBOC','DDIV','DDLS','DDWM','DEEF','DEEP','DEF','DEMZ','DES','DEUS','DFAI','DFAU','DFNV','DGRO','DGRW','DHS','DIA','DIM','DINT','DIV','DJD','DLN','DLS','DMDV','DMRI','DMRL','DMRM','DMRS','DMXF','DNL','DOL','DON','DSI','DSJA','DSOC','DSTL','DURA','DUSA','DVOL','DWAS','DWAT','DWCR','DWM','DWMC','DWPP','DWX','EASG','ECOZ','EDOW','EEH','EES','EFA','EFAD','EFAV','EFAX','EFG','EFIV','EFV','EGIS','EPS','EQAL','EQL','EQRR','EQWL','ERM','ERSX','ESG','ESGA','ESML','ESNG','ETHO','EUSA','EWMC','EWSC','FAB','FAD','FBCG','FBCV','FBGX','FCPI','FDG','FDL','FDLO','FDM','FDMO','FDNI','FDRR','FDT','FDTS','FDVV','FEVR','FEX','FFTG','FGD','FGRO','FICS','FID','FIDI','FIVA','FLGE','FLQH','FLQL','FLQM','FLQS','FLV','FMAG','FMIL','FNDA','FNDB','FNDC','FNDF','FNDX','FNK','FNX','FNY','FPX','FPXI','FQAL','FRLG','FRTY','FTA','FTC','FTCS','FV','FVAL','FVC','FVD','FYC','FYLD','FYT','FYX','GBGR','GBLO','GLRY','GSEW','GSID','GSIE','GSLC','GSPY','GSSC','GSUS','GURU','GVAL','GVIP','GWX','HAIL','HAWX','HDAW','HDEF','HDMV','HDV','HFXI','HIPR','HLAL','HSCZ','HSMV','HUSV','IAPR','ICOW','IDHD','IDHQ','IDIV','IDLB','IDLV','IDMO','IDOG','IDV','IEFA','IFV','IHDG','IJAN','IJH','IJJ','IJK','IJR','IJS','IJT','ILCB','ILCG','ILCV','IMCB','IMCG','IMCV','IMOM','INTF','IPKW','IPO','IPOS','IQDE','IQDF','IQDG','IQDY','IQIN','IQLT','IQSI','IQSU','ISCB','ISCF','ISCG','ISCV','ISDX','ISMD','ISZE','ITOT','IUS','IUSG','IUSS','IUSV','IVAL','IVE','IVOG','IVOO','IVOV','IVV','IVW','IWB','IWC','IWD','IWF','IWL','IWM','IWN','IWO','IWP','IWR','IWS','IWV','IWX','IWY','IXUS','IYY','JDIV','JHMD','JHML','JHMM','JMIN','JMOM','JPIN','JPME','JPSE','JPUS','JQUA','JSMD','JSML','JUST','JVAL','KAPR','KJAN','KJUL','KLCD','KNG','KOMP','KSCD','KVLE','LCG','LCR','LCTU','LGH','LGLV','LRGE','LSAF','LVHD','LVHI','LVOL','LYFE','MAGA','MDY','MDYG','MDYV','MFDX','MFMS','MGC','MGK','MGMT','MGV','MID','MIDF','MMTM','MOAT','MOTI','MSVX','MTUM','MXDU','NAPR','NIFE','NJAN','NOBL','NTSX','NULC','NVQ','OEF','OMFL','OMFS','ONEO','ONEQ','ONEV','ONEY','OSCV','OUSA','OVLH','PALC','PAMC','PBDM','PBSM','PBUS','PDEV','PDN','PDP','PEY','PFM','PID','PIZ','PKW','PQIN','PRF','PRFZ','PSCW','PSCX','PSFD','PSFM','PSMD','PSMR','PTIN','PTLC','PTMC','PTNQ','PWB','PWC','PWV','PXF','QDEF','QDF','QDIV','QDYN','QEFA','QGRO','QINT','QMJ','QQC','QQD','QQEW','QQH','QQQ','QQQE','QQQJ','QQQM','QQQN','QQXT','QRFT','QSY','QUAL','QUS','RBIN','RBUS','RDIV','RDVY','REGL','RESP','RFDA','RFFC','RFG','RFV','RNLC','RNMC','RNSC','RODI','RODM','RORO','RPG','RPV','RSP','RVRS','RWGV','RWJ','RWK','RWL','RWVG','RYJ','RZG','RZV','SCHA','SCHB','SCHC','SCHD','SCHF','SCHG','SCHK','SCHM','SCHV','SCHX','SCZ','SDGA','SDOG','SDY','SECT','SENT','SFYF','SHE','SIXA','SIXH','SIXL','SIXS','SLT','SLY','SLYG','SLYV','SMCP','SMDV','SMLV','SNPE','SPDV','SPDW','SPGP','SPHB','SPHD','SPHQ','SPLG','SPLV','SPMD','SPMO','SPMV','SPQQ','SPSM','SPTM','SPVM','SPVU','SPXE','SPXN','SPXT','SPXV','SPXZ','SPY','SPYG','SPYV','SPYX','SQLV','SSLY','SSUS','STLG','STLV','STNC','STSB','SUSA','SUSL','SVAL','SVOL','SVXY','SYE','SYG','SYLD','SYUS','SYV','TAAG','TADS','TAEQ','TERM','TILT','TLTD','TMDV','TMFC','TPHD','TPIF','TPLC','TPSC','TRTY','TSJA','TSOC','TTAC','TTAI','TUSA','UIVM','ULVM','UMAR','UMAY','USEQ','USLB','USMC','USMF','USMV','USSG','USVM','UTRN','UVXY','VALQ','VB','VBK','VBR','VEA','VEGN','VETS','VEU','VFLQ','VFMF','VFMO','VFMV','VFQY','VFVA','VIG','VIGI','VIIXF','VIOG','VIOO','VIOV','VIRS','VIXM','VLU','VO','VOE','VONE','VONG','VONV','VOOG','VOOV','VOT','VPOP','VRAI','VSDA','VSL','VSMV','VSS','VTHR','VTI','VTRN','VTV','VTWG','VTWO','VTWV','VUG','VUSE','VV','VXF','VXUS','VYM','VYMI','WBIE','WBIF','WBIG','WBIL','WBIN','WBIT','WBIY','WIL','WOMN','WWJD','XDIV','XDQQ','XDSQ','XJH','XJR','XLG','XLSR','XMHQ','XMLV','XMMO','XMVM','XOUT','XRLV','XSHD','XSHQ','XSLV','XSMO','XSVM','XVOL','XVV','XVZ','YLDE','YYY','ZIVZF'],\n",
    "\t# (29)\n",
    "\t'financials': ['BDCZ','BIZD','DFNL','EUFN','FNCL','FXO','IAI','IAK','IAT','IEFN','IXG','IYF','IYG','JHMF','KBE','KBWB','KBWD','KBWP','KBWR','KCE','KIE','KRE','LEND','PFI','PSCF','QABA','RYF','VFH','XLF'],\n",
    "\t# (39)\n",
    "\t'health_care': ['AGNG','ARKG','BBC','BBH','BBP','BMED','BTEC','CNCR','EDOC','FBT','FHLC','FTXH','FXH','HART','HLGE','HTEC','IBB','IBBJ','IBBQ','IEHS','IEIH','IHE','IHF','IHI','IXJ','IYH','PBE','PJP','PPH','PSCH','PTH','RYH','SBIO','VHT','XBI','XHE','XHS','XLV','XPH'],\n",
    "\t# (20)\n",
    "\t'industrials': ['AIRR','EVX','EXI','FIDU','FLM','FXR','ITA','IYJ','IYT','JOYY','KARS','PKB','PPA','PSCI','RGI','ROKT','VIS','XAR','XLI','XTN'],\n",
    "\t# (44)\n",
    "\t'materials': ['AQWA','CGW','COPX','CUT','EBLU','FIW','FMAT','FTAG','FTRI','FXZ','GDX','GDXJ','GNR','GOAU','GOEX','GRES','GUNR','HAP','IGE','IYM','JGLD','LIT','MOO','MXI','NANR','PHO','PIO','PSCM','PYZ','REMX','RING','RTM','SGDJ','SGDM','SIL','SILJ','SLVP','URA','URNM','VAW','VEGI','WOOD','XLB','XME'],\n",
    "\t# (35)\n",
    "\t'real_estate': ['BBRE','DRW','EWRE','FFR','FPRO','FREL','FRI','GQRE','ICF','IFGL','INDS','IYR','KBWY','MORT','NETL','NURE','OLD','PPTY','PSR','RDOG','REIT','REM','REZ','ROOF','RWO','RWR','RWX','SCHH','SRET','SRVR','USRT','VNQ','VNQI','WPS','XLRE'],\n",
    "\t# (66)\n",
    "\t'technology': ['AIQ','ARKF','ARKQ','ARKW','BLCN','BLOK','BTEK','CCON','CIBR','CLOU','DTEC','EKAR','ESPO','FDN','FINX','FITE','FNGS','FTEC','FXL','GAMR','GINN','HACK','IETC','IGM','IGV','IRBO','ITEQ','IXN','IYW','JHMT','KOIN','LRNZ','MOON','NXTG','PNQI','PRNT','PSCT','PSI','PSJ','PTF','PXQ','QTEC','QTUM','ROBT','RYT','SKYY','SMH','SOXQ','SOXX','TDIV','TDV','TECB','THNQ','TPAY','VCAR','VCLO','VFIN','VGT','WCLD','WFH','WUGI','XLK','XNTK','XSD','XSW','XWEB'],\n",
    "\t# (186)\n",
    "\t'trading': ['AGQ','BIB','BIS','BNKD','BNKU','BOIL','BRZU','BZQ','CHAD','CHAU','CLDL','CLDS','CROC','CURE','DDG','DDM','DFEN','DFVL','DFVS','DGLDF','DGP','DGZ','DIG','DOG','DPST','DRIP','DRN','DRV','DSLVF','DUG','DUSL','DUST','DXD','DZZ','EDC','EDZ','EET','EEV','EFO','EFU','EFZ','EMTY','EPV','ERX','ERY','EUFX','EUM','EUO','EURL','EWV','EZJ','FAS','FAZ','FNGD','FNGO','FNGU','FXP','GDXD','GDXU','GLL','GUSH','HDGE','HIBL','HIBS','INDL','IWDL','IWFL','IWML','JDST','JNUG','KOLD','KORU','LABD','LABU','LBJ','LTL','MEXX','MIDU','MJO','MTUL','MVV','MYY','MZZ','NAIL','NUGT','PFFL','PILL','PSQ','PST','QID','QLD','QULL','REK','RETL','REW','ROM','RUSL','RWM','RXD','RXL','SAA','SBB','SBM','SCC','SCDL','SCO','SDD','SDOW','SDP','SDS','SEF','SH','SIJ','SJB','SKF','SKYU','SMDD','SMN','SOXL','SOXS','SPDN','SPUU','SPXL','SPXS','SPXU','SQQQ','SRS','SRTY','SSG','SSO','SZK','TBF','TBT','TBX','TECL','TECS','TMF','TMV','TNA','TPOR','TQQQ','TTT','TVIXF','TWM','TYD','TYO','TZA','UBOT','UBR','UBT','UCC','UCO','UCYB','UDOW','UGAZF','UGE','UGL','UGLDF','UJB','ULE','UMDD','UPRO','UPV','UPW','URE','URTY','USD','USLVF','USML','UST','UTSL','UWM','UXI','UYG','UYM','VIXY','VXX','WANT','WEBL','WEBS','XPP','YANG','YCL','YCS','YINN','YXI'],\n",
    "\t# (17)\n",
    "\t'utilities': ['ECLN','FUTY','FXU','GII','GLIF','IDU','IGF','INFR','JXI','NFRA','PSCU','PUI','RYU','SIMS','TOLZ','VPU','XLU']\n",
    "}\n",
    "\n",
    "class Debugger:\n",
    "\tdef __init__(self, logger=print):\n",
    "\t\tself.logger = logger\n",
    "\n",
    "\tdef _log(self, *args):\n",
    "\t\ttry:\n",
    "\t\t\tdisplay(*args)\n",
    "\t\texcept:\n",
    "\t\t\tself.logger(*args)\n",
    "\n",
    "\tdef display_side_by_side(self, df_list, caption=''):\n",
    "\t\ttry:\n",
    "\t\t\tfrom IPython.display import display_html\n",
    "\t\t\thtml_str = ''\n",
    "\t\t\tfor i in range(len(df_list)):\n",
    "\t\t\t\tdf_styler = df_list[i].style.set_table_attributes(\"style='display:inline; vertical-align: top; margin-right:10px'\")\n",
    "\t\t\t\tif len(caption)>0:\n",
    "\t\t\t\t\tdf_styler = df_styler.set_caption(caption+str(i))\n",
    "\t\t\t\thtml_str += df_styler._repr_html_()\n",
    "\t\t\tdisplay_html(html_str, raw=True)\n",
    "\t\texcept:\n",
    "\t\t\tpass\n",
    "\n",
    "class QCUtils(Debugger):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper().__init__(self.Log)\n",
    "\t\tself.qb = QuantBook()\n",
    "\n",
    "\tdef symbol_helper(self, id):\n",
    "\t\treturn self.qb.Symbol(id).Value\n",
    "\n",
    "\tdef get_data(self, tickers, start_date, end_date, resolution='D'):\n",
    "\t\tresolutions = { 'D': Resolution.Daily, 'H': Resolution.Hour, 'M': Resolution.Minute }\n",
    "\t\tfor ticker in tickers:\n",
    "\t\t\tsymbol = self.qb.AddEquity(ticker, resolutions[resolution]).Symbol # same as using ticker itself\n",
    "\t\tself.raw_history = self.qb.History(self.qb.Securities.Keys, start_date, end_date, resolutions[resolution])\n",
    "\t\tself.df = self.raw_history['close'].unstack(level=0)\n",
    "\t\treturn self.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPipeline(QCUtils):\n",
    "\tdef __init__(self, tickers, start_date, validation_start_date, testing_start_date, end_date):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.start_date = dt.datetime(*start_date)\n",
    "\t\tself.end_date = dt.datetime(*end_date)\n",
    "\t\tself.validation_start_date = dt.datetime(*validation_start_date)\n",
    "\t\tself.testing_start_date = dt.datetime(*testing_start_date)\n",
    "\n",
    "\t\tself.df = self.get_data(tickers, start_date, end_date, 'H') # close price\n",
    "\n",
    "\tdef preprocess_and_split_data(self):\n",
    "\t\t# coordinate start timings for training data\n",
    "\t\tself.coordinate_start_timings(percent=0.95) \n",
    "\n",
    "\t\t# remove outlier data points\n",
    "\t\tself.remove_outlier_data(max_return_threshold=0.2)\n",
    "\n",
    "\t\t# filter out non moving stocks\n",
    "\t\tself.filter_non_moving(max_non_moving_threshold=7)\n",
    "\n",
    "\t\t# filter by volume and price\n",
    "\t\t# \n",
    "\n",
    "\t\tself.training_df = self.df.loc[self.df.index < self.validation_start_date]\n",
    "\t\tself.validation_df = self.df.loc[(self.df.index >= self.validation_start_date) & (self.df.index < self.testing_start_date)]\n",
    "\t\tself.testing_df = self.df.loc[self.df.index >= self.testing_start_date]\n",
    "\t\tself.training_and_validation_df = self.df.loc[self.df.index < self.testing_start_date]\n",
    "\n",
    "\t\tself._log(f'Dataset {self.df.shape[0]} = {self.training_df.shape[0]} + {self.validation_df.shape[0]} + {self.testing_df.shape[0]}') \n",
    "\t\tself._log(f'Train + validation = {self.training_and_validation_df.shape[0]}') \n",
    "\n",
    "\t\treturn self.training_df, self.validation_df, self.testing_df, self.training_and_validation_df\n",
    "\n",
    "\tdef coordinate_start_timings(self, limit=50, percent=0.9):\n",
    "\t\t# need to coordinate start timings for etfs because some were created later\n",
    "\t\told_num_rows = self.df.shape[0]\n",
    "\t\t# removed discontinued etfs whose data is ffill\n",
    "\t\tself._ffill_and_dropna(self.df, limit=limit, thresh=int(percent*old_num_rows)) \n",
    "\n",
    "\t\tidx_to_start = self.df.notnull().all(axis=1).argmax() # first common non na value\n",
    "\n",
    "\t\tself._log(f'Actual start date {self.df.index[idx_to_start]}, removed first {idx_to_start} or {idx_to_start/old_num_rows*100:.2f}% rows')\n",
    "\t\tself.df = self.df.iloc[idx_to_start:]\n",
    "\n",
    "\tdef remove_outlier_data(self, max_return_threshold=0.2):\n",
    "\t\toutlier_returns = self.df.pct_change().abs() > max_return_threshold\n",
    "\t\tsummed_outlier_returns = outlier_returns.sum()\n",
    "\t\tself._log(summed_outlier_returns[summed_outlier_returns > 0])\n",
    "\t\n",
    "\t\tself.df[outlier_returns] = np.nan # remove outlier data\n",
    "\t\tself._ffill_and_dropna(self.df, limit=50) # removed discontinued etfs whose data is ffill\n",
    "\n",
    "\tdef filter_non_moving(self, max_non_moving_threshold=3):\n",
    "\t\tdef consec_repeat_starts(a, n):\n",
    "\t\t\tN = n-1\n",
    "\t\t\tm = a[:-1]==a[1:]\n",
    "\t\t\treturn np.flatnonzero(np.convolve(m,np.ones(N, dtype=int))==N)-N+1\t\n",
    "\t\t\n",
    "\t\tvalid_columns = []\n",
    "\t\tfor col in self.df.columns:\n",
    "\t\t\tif len(consec_repeat_starts(self.df[col].values, max_non_moving_threshold)) == 0:\n",
    "\t\t\t\tvalid_columns.append(col)\n",
    "\n",
    "\t\tself.df = self.df.loc[:, valid_columns]\n",
    "\n",
    "\tdef _ffill_and_dropna(self, df, limit=None, thresh=0):\n",
    "\t\t# returns na columns\n",
    "\t\told_num_cols = df.shape[1]\n",
    "\t\tdf.fillna(method='ffill', inplace=True, limit=limit)\n",
    "\n",
    "\t\tna_columns = df.isna().any()\n",
    "\t\tdf.dropna(axis='columns', inplace=True, thresh=thresh)\n",
    "\t\tself._log(f'{old_num_cols} to {df.shape[1]} columns - {old_num_cols - df.shape[1]} NA columns dropped')\n",
    "\t\tself._log(f'Dropped [{df.columns[na_columns].to_list()}] columns')\n",
    "\n",
    "\t\treturn df.loc[:, na_columns]\n",
    "\n",
    "\tdef plot_data(self):\n",
    "\t\tpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClusterPipeline(Debugger):\n",
    "\tdef __init__(self, pca_factors=15, min_samples=3):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.pca_factors = pca_factors\n",
    "\t\tself.min_samples = min_samples\n",
    "\n",
    "\tdef _ffill_and_dropna(self, df, caption, limit=None):\n",
    "\t\told_shape = df.shape[1]\n",
    "\t\tdf.fillna(method='ffill', inplace=True, limit=limit)\n",
    "\t\tdf.dropna(axis='columns', inplace=True)\n",
    "\t\tself._log(f'{caption} - {old_shape} to {df.shape[1]} columns - {old_shape - df.shape[1]} NA columns dropped')\n",
    "\n",
    "\tdef find_clusters(self, df):\n",
    "\t\tR = df.pct_change().iloc[1:, :] # here the columns of R are the different observations.\n",
    "\t\tself._ffill_and_dropna(R, 'R', 10) # avoid any stocks with missing returns\n",
    "\t\tnorm_R = (R - R.mean()) / R.std()\n",
    "\t\tself._ffill_and_dropna(norm_R, 'Norm R', 10) # avoid any stocks with missing returns\n",
    "\n",
    "\t\tpca = PCA()\n",
    "\t\tpca.fit(norm_R.T) # use returns as columns and stocks as rows\n",
    "\t\tpca_data = pca.transform(norm_R.T) # get PCA coordinates for scaled_data\n",
    "\n",
    "\t\tX = pca_data[:, :self.pca_factors]\n",
    "\t\tX = pd.DataFrame(X, columns=['PC'+str(i) for i in range(1, self.pca_factors+1)], index=norm_R.columns)\n",
    "\n",
    "\t\tself._log(f'{np.sum(pca.explained_variance_ratio_[:self.pca_factors] * 100)}% of variance - {self.pca_factors} components')\n",
    "\n",
    "\t\toptics_model = OPTICS(min_samples=self.min_samples)\n",
    "\t\t# min_samples parameter -> min number of samples required to form a dense region\n",
    "\t\t# xi parameter -> max distance between two samples to be considered as a neighborhood\n",
    "\t\t# min_cluster_size -> min size of a dense region to be considered as a cluster\n",
    "\n",
    "\t\tclustering = optics_model.fit(X)\n",
    "\t\tclusters = []\n",
    "\t\tfor i in range(len(set(optics_model.labels_))-1):\n",
    "\t\t\tcluster = list(X[optics_model.labels_==i].index)\n",
    "\t\t\tclusters.append(cluster)\n",
    "\n",
    "\t\tself.plot_clusters(pca, optics_model, X)\n",
    "\n",
    "\t\treturn clusters\n",
    "\n",
    "\tdef plot_clusters(self, pca, optics_model, X):\n",
    "\t\tif not self.display_graphs:\n",
    "\t\t\treturn\n",
    "\t\t# PCA plot\n",
    "\t\tper_var = np.round(pca.explained_variance_ratio_* 100, decimals=1)\n",
    "\t\tlabels = ['PC' + str(x) for x in range(1, len(per_var)+1)]\n",
    "\t\tplt.figure(figsize=(5, 3))\n",
    "\t\tplt.bar(x=range(1,len(per_var)+1), height=per_var, tick_label=labels)\n",
    "\t\tplt.ylabel('Percentage of Explained Variance')\n",
    "\t\tplt.xlabel('Principal Component')\n",
    "\t\tplt.title('Scree Plot')\n",
    "\t\tplt.show()\n",
    "\n",
    "\t\t# Cluster plots\n",
    "\t\tspace = np.arange(len(X))\n",
    "\t\treachability = optics_model.reachability_[optics_model.ordering_]\n",
    "\t\tlabels = optics_model.labels_[optics_model.ordering_]\n",
    "\n",
    "\t\tplt.figure(figsize=(12, 3))\n",
    "\t\tG = gridspec.GridSpec(1, 3)\n",
    "\t\tax1 = plt.subplot(G[0, :2])\n",
    "\t\tax2 = plt.subplot(G[0, -1])\n",
    "\n",
    "\t\tcolors = ['r', 'g','b','c','y','m', 'coral', 'darkgreen', 'crimson', 'darkblue', 'ivory', 'khaki', 'r', 'g','b','c','y','m', 'coral', 'darkgreen', 'crimson', 'darkblue', 'ivory', 'khaki', 'r', 'g','b','c','y','m']\n",
    "\n",
    "\t\tassert len(set(labels)) <= len(colors)\n",
    "\n",
    "\t\tfor i, color in enumerate(colors):\n",
    "\t\t\tXk = space[labels == i]\n",
    "\t\t\tRk = reachability[labels == i]\n",
    "\t\t\tax1.plot(Xk, Rk, color, alpha = 0.3, marker='.')\n",
    "\t\t\tax1.plot(space[labels == -1], reachability[labels == -1], 'k.', alpha = 0.3)\n",
    "\t\t\tax1.plot(space, np.full_like(space, 2., dtype = float), 'k-', alpha = 0.5)\n",
    "\t\t\tax1.plot(space, np.full_like(space, 0.5, dtype = float), 'k-.', alpha = 0.5)\n",
    "\t\t\tax1.set_ylabel('Reachability Distance')\n",
    "\t\t\tax1.set_title('Reachability Plot')\n",
    "\n",
    "\t\t# Plotting the OPTICS Clustering\n",
    "\t\tfor i, color in enumerate(colors):\n",
    "\t\t\tXk = X[optics_model.labels_ == i]\n",
    "\t\t\tax2.plot(Xk.iloc[:, 0], Xk.iloc[:, 1], color, alpha = 0.3, marker='.')\n",
    "\t\t\tax2.plot(X.iloc[optics_model.labels_ == -1, 0], X.iloc[optics_model.labels_ == -1, 1],'k+', alpha = 0.1)\n",
    "\t\t\tax2.set_title('OPTICS Clustering')\n",
    "\n",
    "\t\tplt.tight_layout()\n",
    "\t\tplt.show()\n",
    "\n",
    "\t\tself.display_side_by_side([pd.DataFrame({'Name': map(self.symbol_helper, cluster)}) for cluster in clusters], 'Cluster ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PortfolioPipeline(Debugger):\n",
    "\tdef __init__(self, p_value_threshold=0.01, max_half_life=60):\n",
    "\t\tsuper().__init__()\n",
    "\t \t# stationarity tests\n",
    "\t\tself.p_value_threshold = p_value_threshold\n",
    "\t\tself.min_half_life, self.max_half_life = 0, max_half_life # I want 1 week half life\n",
    "\t\tself.avg_cross_period_threshold = int(self.max_half_life * 0.75) # i'll just make it less strict for now\n",
    "\n",
    "\tdef estimate_long_run_short_run_relationships(self, y, x):\n",
    "\t\tassert isinstance(y, pd.Series), 'Input series y should be of type pd.Series'\n",
    "\t\tassert isinstance(x, pd.Series), 'Input series x should be of type pd.Series'\n",
    "\t\tassert sum(y.isnull()) == 0, 'Input series y has nan-values. Unhandled case.'\n",
    "\t\tassert sum(x.isnull()) == 0, 'Input series x has nan-values. Unhandled case.'\n",
    "\t\tassert y.index.equals(x.index), 'The two input series y and x do not have the same index.'\n",
    "\t\t\n",
    "\t\tx = sm.add_constant(x)\n",
    "\t\tlong_run_ols = sm.OLS(y, x)\n",
    "\t\tlong_run_ols_fit = long_run_ols.fit()\n",
    "\t\t\n",
    "\t\tc, gamma = long_run_ols_fit.params\n",
    "\t\tz = long_run_ols_fit.resid\n",
    "\n",
    "\t\tshort_run_ols = OLS(y.diff().iloc[1:], (z.shift().iloc[1:]))\n",
    "\t\tshort_run_ols_fit = short_run_ols.fit()\n",
    "\t\t\n",
    "\t\talpha = short_run_ols_fit.params[0]\n",
    "\t\t\t\t\n",
    "\t\treturn c, gamma, alpha, z\n",
    "\n",
    "\tdef engle_granger_two_step_cointegration_test(self, y, x):\n",
    "\t\tassert isinstance(y, pd.Series), 'Input series y should be of type pd.Series'\n",
    "\t\tassert isinstance(x, pd.Series), 'Input series x should be of type pd.Series'\n",
    "\t\tassert sum(y.isnull()) == 0, 'Input series y has nan-values. Unhandled case.'\n",
    "\t\tassert sum(x.isnull()) == 0, 'Input series x has nan-values. Unhandled case.'\n",
    "\t\tassert y.index.equals(x.index), 'The two input series y and x do not have the same index.'\n",
    "\t\t\n",
    "\t\tc, gamma, alpha, z = self.estimate_long_run_short_run_relationships(y, x)\n",
    "\t\t\n",
    "\t\t# NOTE: The p-value returned by the adfuller function assumes we do not estimate z first, but test \n",
    "\t\t# stationarity of an unestimated series directly. This assumption should have limited effect for high N, \n",
    "\t\t# so for the purposes of this course this p-value can be used for the EG-test. Critical values taking \n",
    "\t\t# this into account more accurately are provided in e.g. McKinnon (1990) and Engle & Yoo (1987).\n",
    "\t\t\n",
    "\t\tadfstat, pvalue, usedlag, nobs, crit_values = adfuller(z, maxlag=1, autolag=None)\n",
    "\t\n",
    "\t\treturn c, gamma, alpha, z, adfstat, pvalue\n",
    "\n",
    "\tdef stationarity_check(self, df, stock1, stock2):\n",
    "\t\tprice_series1, price_series2 = df[stock1], df[stock2]\n",
    "\n",
    "\t\tconstant, beta, alpha, residual, adfstat, p_value = self.engle_granger_two_step_cointegration_test(price_series1, price_series2)\n",
    "\n",
    "\t\tH, half_life, avg_cross_period = None, None, None\n",
    "\n",
    "\t\tif not(p_value <= self.p_value_threshold):\n",
    "\t\t\treturn 0, constant, beta, alpha, residual, p_value, H, half_life, avg_cross_period # first number is index failed to track failed count\n",
    "\n",
    "\t\t# Hurst Exponent\n",
    "\t\tH, c, _data = compute_Hc(residual)\n",
    "\t\tif H >= 0.5: # spread is not mean-reverting\n",
    "\t\t\treturn 1, constant, beta, alpha, residual, p_value, H, half_life, avg_cross_period\n",
    "\n",
    "\t\t# Half-life - duration to mean-revert\n",
    "\t\thalf_life = -np.log(2) / alpha\n",
    "\t\tif not(self.min_half_life <= half_life and half_life <= self.max_half_life):\n",
    "\t\t\treturn 2, constant, beta, alpha, residual, p_value, H, half_life, avg_cross_period\n",
    "\n",
    "\t\t# Mean cross frequency\n",
    "\t\tresid = np.array(residual)\n",
    "\t\ttotal_crosses = ((resid[:-1] * resid[1:]) < 0).sum()\n",
    "\t\tavg_cross_period = len(price_series1) / total_crosses\n",
    "\t\tif avg_cross_period > self.avg_cross_period_threshold:\n",
    "\t\t\treturn 3, constant, beta, alpha, residual, p_value, H, half_life, avg_cross_period\n",
    "\t\t\n",
    "\t\tassert abs(residual.mean()) <= 1e-9\n",
    "\n",
    "\t\treturn -1, constant, beta, alpha, residual, p_value, H, half_life, avg_cross_period\n",
    "\n",
    "\tdef find_pairs_from_clusters(self, df, clusters):\n",
    "\t\tcluster_pairs = []\n",
    "\t\tfailed_count = [0]*4\n",
    "\t\ttotal_num_of_pairs = 0\n",
    "\n",
    "\t\tfor cluster_idx, cluster in enumerate(clusters):\n",
    "\t\t\tn = len(cluster)\n",
    "\t\t\tnum_of_pairs = n*(n-1)//2\n",
    "\t\t\ttotal_num_of_pairs += num_of_pairs\n",
    "\n",
    "\t\t\tcluster_data = { 'Stock1': [], 'Stock2': [], 'Beta': [], 'p': [], 'H': [], 'Half-life': [], 'Avg zero cross period': [], 'Cluster': [] }\n",
    "\t\t\tself._log(f'Testing {num_of_pairs} pairs in cluster {cluster_idx}')\n",
    "\n",
    "\t\t\tfor i in range(n):\n",
    "\t\t\t\tfor j in range(i+1, n):\n",
    "\t\t\t\t\tfailed_idx, constant, beta, alpha, residual, p_value, H, half_life, avg_cross_period = self.stationarity_check(df, cluster[i], cluster[j])\n",
    "\t\t\t\t\tif failed_idx != -1:\n",
    "\t\t\t\t\t\tfailed_count[failed_idx] += 1\n",
    "\t\t\t\t\t\tcontinue\n",
    "\n",
    "\t\t\t\t\tif beta < 0:\n",
    "\t\t\t\t\t\tself._log(f'Found pair with negative beta - {cluster[i]} {cluster[j]}')\n",
    "\t\t\t\t\t\tcontinue\n",
    "\n",
    "\t\t\t\t\tcluster_data['Stock1'].append(cluster[i])\n",
    "\t\t\t\t\tcluster_data['Stock2'].append(cluster[j])\n",
    "\t\t\t\t\tcluster_data['Beta'].append(beta)\n",
    "\t\t\t\t\tcluster_data['p'].append(p_value)\n",
    "\t\t\t\t\tcluster_data['H'].append(H)\n",
    "\t\t\t\t\tcluster_data['Half-life'].append(half_life)\n",
    "\t\t\t\t\tcluster_data['Avg zero cross period'].append(int(avg_cross_period))\n",
    "\t\t\t\t\tcluster_data['Cluster'].append(int(cluster_idx))\n",
    "\n",
    "\n",
    "\t\t\tcluster_pairs.append(pd.DataFrame(cluster_data))\n",
    "\n",
    "\t\tself._log(f'Tested {total_num_of_pairs} pairs in total')\n",
    "\t\tself._log(f'{failed_count[0]} failed cointegration test')\n",
    "\t\tself._log(f'{failed_count[1]} failed H exp criterion')\n",
    "\t\tself._log(f'{failed_count[2]} failed half-life criterion')\n",
    "\t\tself._log(f'{failed_count[3]} failed avg zero cross period criterion')\n",
    "\n",
    "\t\tif len(cluster_pairs) == 0:\n",
    "\t\t\treturn None\n",
    "\t\tpairs = pd.concat(cluster_pairs, ignore_index=True)\n",
    "\t\tself._log(f'Found {pairs.shape[0]} pairs')\n",
    "\t\tself._log(pairs)\n",
    "\n",
    "\t\treturn pairs\n",
    "\n",
    "\tdef filter_positive_pnl_pairs(self, validated_pairs, sorted_validation_backtest_results, min_validation_return_threshold=0.1):\n",
    "\t\tpositive_pnl_pairs = list(filter(lambda x: x[-1][-1]-x[-1][0]>0, sorted_validation_backtest_results))\n",
    "\n",
    "\t\tfiltered_validated_pairs_data = { 'Stock1': [], 'Stock2': [], 'Beta': [], 'p': [], 'H': [], 'Half-life': [], 'Avg zero cross period': [], 'Cluster': [], 'Best entry z threshold': [], 'Best exit z threshold': [], 'Validation Fees': [], 'Validation PnL': [] }\n",
    "\n",
    "\t\tfor (pair_df, training_pair_df, stock1, stock2, beta, best_entry_z_threshold, best_exit_z_threshold, best_position, best_fees, best_margin) in positive_pnl_pairs:\n",
    "\t\t\tvalidation_pnl = best_margin[-1]-best_margin[0]\n",
    "\t\t\tvalidation_return = (best_margin[-1]-best_margin[0]) / best_margin[0]\n",
    "\t\t\tif validation_return < min_validation_return_threshold:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\tdf = validated_pairs.loc[(validated_pairs['Stock1']==stock1) & (validated_pairs['Stock2']==stock2), :]\n",
    "\t\t\tfor col in df.columns:\n",
    "\t\t\t\tfiltered_validated_pairs_data[col].append(df[col].values[0])\n",
    "\t\t\tfiltered_validated_pairs_data['Best entry z threshold'].append(best_entry_z_threshold)\n",
    "\t\t\tfiltered_validated_pairs_data['Best exit z threshold'].append(best_exit_z_threshold)\n",
    "\t\t\tfiltered_validated_pairs_data['Validation Fees'].append(np.sum(best_fees))\n",
    "\t\t\tfiltered_validated_pairs_data['Validation PnL'].append(validation_pnl)\n",
    "\n",
    "\t\tfiltered_validated_pairs = pd.DataFrame(filtered_validated_pairs_data)\n",
    "\n",
    "\t\tself._log(f'Sector {sector}: {len(positive_pnl_pairs)}/{len(sorted_validation_backtest_results)} = {len(positive_pnl_pairs) / len(sorted_validation_backtest_results)*100:.2f}% have +PnL')\n",
    "\t\tself._log(filtered_validated_pairs)\n",
    "\t\treturn filtered_validated_pairs\n",
    "\n",
    "\n",
    "\tdef revalidate_pairs(self, df, validated_pairs, sector):\n",
    "\t\ttest_pairs_data = { 'Stock1': [], 'Stock2': [], 'Beta': [], 'p': [], 'H': [], 'Half-life': [], 'Avg zero cross period': [], 'Cluster': [], 'Best entry z threshold': [], 'Best exit z threshold': [], 'Validation Fees': [], 'Validation PnL': [], 'Sector': [] }\n",
    "\t\tfailed_count = [0]*4\n",
    "\t\told_num_pairs = validated_pairs.shape[0]\n",
    "\n",
    "\t\tself._log(f'Testing {old_num_pairs} pairs')\n",
    "\n",
    "\t\tfor stock1, stock2, _, _, _, _, _, cluster, best_entry_z_threshold, best_exit_z_threshold, validation_fees, validation_pnl in validated_pairs.values:\n",
    "\t\t\tfailed_idx, constant, beta, alpha, residual, p_value, H, half_life, avg_cross_period = self.stationarity_check(df, stock1, stock2)\n",
    "\t\t\tif failed_idx != -1:\n",
    "\t\t\t\tfailed_count[failed_idx] += 1\n",
    "\t\t\t\tcontinue\n",
    "\n",
    "\t\t\ttest_pairs_data['Stock1'].append(stock1)\n",
    "\t\t\ttest_pairs_data['Stock2'].append(stock2)\n",
    "\t\t\ttest_pairs_data['Beta'].append(beta)\n",
    "\t\t\ttest_pairs_data['p'].append(p_value)\n",
    "\t\t\ttest_pairs_data['H'].append(H)\n",
    "\t\t\ttest_pairs_data['Half-life'].append(half_life)\n",
    "\t\t\ttest_pairs_data['Avg zero cross period'].append(int(avg_cross_period))\n",
    "\t\t\ttest_pairs_data['Cluster'].append(int(cluster))\n",
    "\t\t\ttest_pairs_data['Best entry z threshold'].append(best_entry_z_threshold)\n",
    "\t\t\ttest_pairs_data['Best exit z threshold'].append(best_exit_z_threshold)\n",
    "\t\t\ttest_pairs_data['Validation Fees'].append(validation_fees)\n",
    "\t\t\ttest_pairs_data['Validation PnL'].append(validation_pnl)\n",
    "\t\t\ttest_pairs_data['Sector'].append(sector)\n",
    "\n",
    "\t\ttest_pairs = pd.DataFrame(test_pairs_data)\n",
    "\t\tnew_num_pairs = test_pairs.shape[0]\n",
    "\n",
    "\t\tself._log(f'{new_num_pairs}/{old_num_pairs} ({new_num_pairs/old_num_pairs*100:.2f}%) passed stationary check')\n",
    "\t\tself._log(f'{failed_count[0]} failed cointegration test')\n",
    "\t\tself._log(f'{failed_count[1]} failed H exp criterion')\n",
    "\t\tself._log(f'{failed_count[2]} failed half-life criterion')\n",
    "\t\tself._log(f'{failed_count[3]} failed avg zero cross period criterion')\n",
    "\n",
    "\t\tself._log(test_pairs)\n",
    "\n",
    "\t\treturn test_pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BacktestPipeline(Debugger):\n",
    "\tdef __init__(self, percent_margin_buffer=0.1):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.percent_margin_buffer = percent_margin_buffer\n",
    "\n",
    "\tdef validation_backtest(self, training_df, validation_df, pairs, initial_capital=1000):\n",
    "\t\tvalidation_backtest_results = []\n",
    "\n",
    "\t\tfor stock1, stock2, beta, p, H, half_life, avg_cross_period, cluster_idx in pairs.values:\n",
    "\t\t\t# self._log(f'Simulating pair [{self.symbol_helper(stock1)}-{self.symbol_helper(stock2)}]')\n",
    "\t\t\tpair_df = validation_df.loc[:, [stock1, stock2]]\n",
    "\t\t\ttraining_pair_df = training_df.loc[:, [stock1, stock2]]\n",
    "\n",
    "\t\t\tpair_df_spread = pair_df[stock1] - beta * pair_df[stock2]\n",
    "\t\t\ttraining_pair_df_spread = training_pair_df[stock1] - beta * training_pair_df[stock2]\n",
    "\n",
    "\t\t\tmean = np.mean(training_pair_df_spread)\n",
    "\t\t\tstd = np.std(training_pair_df_spread)\n",
    "\n",
    "\t\t\t# center spread \n",
    "\t\t\tpair_df['z'] = (pair_df_spread - mean) / std\n",
    "\t\t\ttraining_pair_df['z'] = (training_pair_df_spread - mean) / std\n",
    "\n",
    "\t\t\tbest_final_pnl = -1e9\n",
    "\t\t\tbest_entry_z_threshold, best_exit_z_threshold = None, None\n",
    "\t\t\tbest_position, best_fees, best_margin = None, None, None\n",
    "\t\t\t\n",
    "\t\t\tfor entry_z_threshold in np.linspace(1.0, 2.5, 5):\n",
    "\t\t\t\tfor exit_z_threshold in np.linspace(0.0, 1.0, 4):\n",
    "\t\t\t\t\tposition, margin, fees = self.backtest(pair_df, stock1, stock2, beta, initial_capital, entry_z_threshold, exit_z_threshold)\n",
    "\t\t\t\t\tfinal_pnl = margin[-1]\n",
    "\t\t\t\t\tif final_pnl > best_final_pnl:\n",
    "\t\t\t\t\t\tbest_final_pnl = final_pnl\n",
    "\t\t\t\t\t\tbest_entry_z_threshold, best_exit_z_threshold = entry_z_threshold, exit_z_threshold\n",
    "\t\t\t\t\t\tbest_position = position\n",
    "\t\t\t\t\t\tbest_margin = margin\n",
    "\t\t\t\t\t\tbest_fees = fees\n",
    "\t\t\t\n",
    "\t\t\tvalidation_backtest_results.append((pair_df, training_pair_df, stock1, stock2, beta, best_entry_z_threshold, best_exit_z_threshold, best_position, best_fees, best_margin))\n",
    "\n",
    "\t\treturn validation_backtest_results\n",
    "\n",
    "\tdef backtest(self, pair_df, stock1, stock2, beta, initial_capital, entry_z_threshold=2.0, exit_z_threshold=0.5):\n",
    "\t\tposition = { stock1: [0], stock2: [0] }\n",
    "\t\tcapital = initial_capital\n",
    "\t\tmargin = [capital]\n",
    "\t\tfees = [(0, 0, 0)]\n",
    "\n",
    "\t\tfor time, data_at_time in pair_df.iterrows():\n",
    "\t\t\tstock1_close = data_at_time[stock1]\n",
    "\t\t\tstock2_close = data_at_time[stock2]\n",
    "\t\t\tcur_z_spread = data_at_time['z']\n",
    "\n",
    "\t\t\tposition_direction = np.sign(position[stock1][-1])\n",
    "\n",
    "\t\t\tstock1_shares, stock2_shares = 0, 0\n",
    "\t\t\tcommission, slippage, short_rental = 0, 0, 0\n",
    "\n",
    "\t\t\tusable_capital = capital * (1-self.percent_margin_buffer)\n",
    "\t\t\tif position_direction == 0:\n",
    "\t\t\t\tif (cur_z_spread <= -entry_z_threshold or cur_z_spread >= entry_z_threshold):\n",
    "\t\t\t\t\t# adding the / 2 to avoid margin calls??? im p sure this isnt right tho\n",
    "\t\t\t\t\tif beta > 1:\n",
    "\t\t\t\t\t\tstock2_shares = min(np.floor(usable_capital / stock2_close / 2), np.floor(usable_capital / stock1_close * beta / 2))\n",
    "\t\t\t\t\t\tstock1_shares = np.ceil(stock2_shares / beta)\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tstock1_shares = min(np.floor(usable_capital / stock1_close / 2), np.floor(usable_capital / stock2_close / beta / 2))\n",
    "\t\t\t\t\t\tstock2_shares = np.ceil(stock1_shares * beta)\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\tassert stock1_shares > 0\n",
    "\t\t\t\t\tassert stock2_shares > 0\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t\t\tis_long = cur_z_spread <= -entry_z_threshold\n",
    "\n",
    "\t\t\t\t\tposition[stock1].append(stock1_shares if is_long else -stock1_shares)\n",
    "\t\t\t\t\tposition[stock2].append(-stock2_shares if is_long else stock2_shares)\n",
    "\t\t\t\t\tpos_stock1, pos_stock2 = position[stock1][-1], position[stock2][-1]\n",
    "\n",
    "\t\t\t\t\tportfolio_value = pos_stock1 * stock1_close + pos_stock2 * stock2_close\n",
    "\t\t\t\t\tcommission = 0.0008 * (abs(pos_stock1) * stock1_close + abs(pos_stock2) * stock2_close)\n",
    "\t\t\t\t\tslippage = 0.0020 * (abs(pos_stock1) * stock1_close + abs(pos_stock2) * stock2_close)\n",
    "\t\t\t\t\tcapital -= slippage + commission\n",
    "\t\t\t\t\tcapital -= portfolio_value\n",
    "\t\t\t\t\tassert capital >= 0, (commission, slippage, portfolio_value, pos_stock1*stock1_close, pos_stock2*stock2_close, pos_stock1, pos_stock2, stock1_close, stock2_close, beta)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tposition[stock1].append(0)\n",
    "\t\t\t\t\tposition[stock2].append(0)\n",
    "\t\t\telse:\n",
    "\t\t\t\tshort_rental = -position[stock2][-1] * stock2_close * 0.01/252 if position_direction > 0 else -position[stock1][-1] * stock1_close * 0.01/252\n",
    "\t\t\t\tcapital -= short_rental\n",
    "\t\t\t\tif ((position_direction > 0 and cur_z_spread >= exit_z_threshold) or (position_direction < 0 and cur_z_spread <= -exit_z_threshold)):\n",
    "\t\t\t\t\tpos_stock1, pos_stock2 = position[stock1][-1], position[stock2][-1]\n",
    "\t\t\t\t\tportfolio_value = pos_stock1 * stock1_close + pos_stock2 * stock2_close\n",
    "\t\t\t\t\tcommission = 0.0008 * (abs(pos_stock1) * stock1_close + abs(pos_stock2) * stock2_close)\n",
    "\t\t\t\t\tslippage = 0.0020 * (abs(pos_stock1) * stock1_close + abs(pos_stock2) * stock2_close)\n",
    "\t\t\t\t\tcapital -= commission + slippage\n",
    "\t\t\t\t\tcapital += portfolio_value\n",
    "\n",
    "\t\t\t\t\tposition[stock1].append(0)\n",
    "\t\t\t\t\tposition[stock2].append(0)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tposition[stock1].append(position[stock1][-1])\n",
    "\t\t\t\t\tposition[stock2].append(position[stock2][-1])\n",
    "\t\t\t\n",
    "\t\t\tpos_stock1, pos_stock2 = position[stock1][-1], position[stock2][-1]\n",
    "\t\t\tportfolio_value = pos_stock1 * stock1_close + pos_stock2 * stock2_close\n",
    "\t\t\tmargin.append(capital + portfolio_value) # store margin if liquidated everything at point in time\n",
    "\t\t\tfees.append((commission, slippage, short_rental))\n",
    "\n",
    "\t\treturn position, margin, fees\n",
    "\n",
    "\tdef plot_validation_backtest_results(self, results):\n",
    "\t\tfor (pair_df, training_pair_df, stock1, stock2, beta, best_entry_z_threshold, best_exit_z_threshold, best_position, best_fees, best_margin) in results:\n",
    "\t\t\tself._log(f'[{self.symbol_helper(stock1)} {self.symbol_helper(stock2)}] Best entry z threshold: {best_entry_z_threshold:.3f} Best exit z threshold: {best_exit_z_threshold:.3f} Cum PnL: {(best_margin[-1]-best_margin[0]):.3f}')\n",
    "\t\t\tself.plot_pair_backtest(pair_df, training_pair_df, stock1, stock2, beta, best_entry_z_threshold, best_exit_z_threshold, best_position, best_fees, best_margin)\n",
    "\n",
    "\tdef plot_pair_backtest(self, pair_df, training_pair_df, stock1, stock2, beta, entry_z_threshold, exit_z_threshold, position, fees, margin):\n",
    "\t\tplt.figure(figsize =(12, 5))\n",
    "\t\tG = gridspec.GridSpec(2, 3)\n",
    "\t\tax1 = plt.subplot(G[0, 0])\n",
    "\t\tax2 = plt.subplot(G[0, 1])\n",
    "\t\tax3 = plt.subplot(G[0, 2])\n",
    "\t\tax4 = plt.subplot(G[1, 0])\n",
    "\t\tax5 = plt.subplot(G[1, 1])\n",
    "\t\tax6 = plt.subplot(G[1, 2])\n",
    "\n",
    "\t\tstock1_symbol = self.symbol_helper(stock1)\n",
    "\t\tstock2_symbol = self.symbol_helper(stock2)\n",
    "\n",
    "\t\ttime = np.concatenate([training_pair_df.index, pair_df.index])\n",
    "\n",
    "\t\t# plot pairs individual price\n",
    "\t\tax1.plot(time, np.concatenate([training_pair_df[stock1], pair_df[stock1]]), 'r', label=stock1_symbol)\n",
    "\t\tax1.plot(time, np.concatenate([training_pair_df[stock2], pair_df[stock2]]), 'g', label=stock2_symbol)\n",
    "\t\tax1.axvline(x=pair_df.index[0], ymin=0, ymax=1, linewidth=1, color='b')\n",
    "\t\tax1.set_xlabel('Date')\n",
    "\t\tax1.set_title('Close price pair comparison')\n",
    "\t\tax1.legend()\n",
    "\n",
    "\t\t# plot z spread price\n",
    "\t\tax2.plot(time, np.concatenate([training_pair_df['z'], pair_df['z']]), 'c', label=f'z = norm {stock1_symbol}-{beta:.2f}*{stock2_symbol}')\n",
    "\t\tax2.axvline(x=pair_df.index[0], ymin=0, ymax=1, linewidth=1, color='b')\n",
    "\n",
    "\t\tpos_stock1 = np.array(position[stock1])[1:]\n",
    "\t\tpos_stock2 = np.array(position[stock2])[1:]\n",
    "\t\tnp_margin = np.array(margin)\n",
    "\n",
    "\t\tlong_indices = pos_stock1 > 0\n",
    "\t\tshort_indices = pos_stock1 < 0\n",
    "\t\tax2.plot(pair_df.index[long_indices], pair_df.loc[long_indices, 'z'], 'g.')\n",
    "\t\tax2.plot(pair_df.index[short_indices], pair_df.loc[short_indices, 'z'], 'r.')\n",
    "\t\tax2.axhline(y=entry_z_threshold, xmin=0, xmax=1, linewidth=1, color='m')\n",
    "\t\tax2.axhline(y=-entry_z_threshold, xmin=0, xmax=1, linewidth=1, color='m')\n",
    "\t\tax2.axhline(y=exit_z_threshold, xmin=0, xmax=1, linewidth=1, color='brown')\n",
    "\t\tax2.axhline(y=-exit_z_threshold, xmin=0, xmax=1, linewidth=1, color='brown')\n",
    "\t\tax2.set_xlabel('Date')\n",
    "\t\tax2.set_title('z')\n",
    "\t\tax2.legend()\n",
    "\n",
    "\t\t# margin, fees, and drawdown got one extra starting pt\n",
    "\t\t# plot cumulative pnl\n",
    "\t\tax3.plot(np_margin)\n",
    "\t\tax3.set_title('Margin')\n",
    "\n",
    "\t\t# plot fees\n",
    "\t\tnp_fees = np.array(fees)\n",
    "\t\tcumsum_fees = np.cumsum(np_fees, axis=0)\n",
    "\t\tcumsum_total_fees = np.sum(cumsum_fees, axis=1)\n",
    "\t\tax4.plot(cumsum_fees[:, 0], label='commission')\n",
    "\t\tax4.plot(cumsum_fees[:, 1], label='slippage')\n",
    "\t\tax4.plot(cumsum_fees[:, 2], label='short rental')\n",
    "\t\tax4.plot(cumsum_total_fees, label='total')\n",
    "\t\tax4.set_title('Fees')\n",
    "\t\tax4.legend()\n",
    "\n",
    "\t\t# plot exposure \n",
    "\t\tstock1_invested = pair_df[stock1] * pos_stock1\n",
    "\t\tstock2_invested = pair_df[stock2] * pos_stock2\n",
    "\t\tnet_exposure = stock1_invested + stock2_invested\n",
    "\t\tabs_exposure = np.absolute(stock1_invested) + np.absolute(stock2_invested)\n",
    "\t\tax5.plot(stock1_invested, label='stock1')\n",
    "\t\tax5.plot(stock2_invested, label='stock2')\n",
    "\t\tax5.plot(net_exposure, label='net exposure')\n",
    "\t\tax5.plot(abs_exposure, label='abs exposure')\n",
    "\t\tax5.set_title('Exposure')\n",
    "\t\tax5.legend()\n",
    "\n",
    "\t\t# plot drawdown\n",
    "\t\tcumret = np_margin / np_margin[0] - 1\n",
    "\t\thighwatermark=np.zeros(cumret.shape)\n",
    "\t\tdrawdown=np.zeros(cumret.shape)\n",
    "\t\tdrawdownduration=np.zeros(cumret.shape)\n",
    "\t\t\n",
    "\t\tfor t in np.arange(1, cumret.shape[0]):\n",
    "\t\t\thighwatermark[t]=np.maximum(highwatermark[t-1], cumret[t])\n",
    "\t\t\tdrawdown[t]=(1+cumret[t])/(1+highwatermark[t])-1\n",
    "\t\t\tif drawdown[t]==0:\n",
    "\t\t\t\tdrawdownduration[t]=0\n",
    "\t\t\telse:\n",
    "\t\t\t\tdrawdownduration[t]=drawdownduration[t-1]+1\n",
    "\t\t\t\t\n",
    "\t\tmaxDD, i=np.min(drawdown), np.argmin(drawdown) # drawdown < 0 always\n",
    "\t\tmaxDDD=np.max(drawdownduration)\n",
    "\t\t\n",
    "\t\tax6.plot(drawdown)\n",
    "\t\tax6.set_title('Drawdown')\n",
    "\n",
    "\t\tplt.tight_layout()\n",
    "\t\tplt.show()\n",
    "\t\n",
    "\t\n",
    "\tdef test_backtest(self, training_and_validation_df, testing_df, test_pairs, initial_capital=1000):\n",
    "\t\ttest_backtest_results = {}\n",
    "\n",
    "\t\tfor stock1, stock2, beta, p, H, half_life, avg_cross_period, cluster, best_entry_z_threshold, best_exit_z_threshold, validation_fees, validation_pnl, sector in test_pairs.values:\n",
    "\t\t\t# self._log(f'Simulating pair [{self.symbol_helper(stock1)}-{self.symbol_helper(stock2)}]')\n",
    "\t\t\tpair_df = testing_df.loc[:, [stock1, stock2]]\n",
    "\t\t\ttraining_pair_df = training_and_validation_df.loc[:, [stock1, stock2]]\n",
    "\n",
    "\t\t\tpair_df_spread = pair_df[stock1] - beta * pair_df[stock2]\n",
    "\t\t\ttraining_pair_df_spread = training_pair_df[stock1] - beta * training_pair_df[stock2]\n",
    "\n",
    "\t\t\tmean = np.mean(training_pair_df_spread)\n",
    "\t\t\tstd = np.std(training_pair_df_spread)\n",
    "\n",
    "\t\t\tpair_df['z'] = (pair_df_spread - mean) / std\n",
    "\t\t\ttraining_pair_df['z'] = (training_pair_df_spread - mean) / std\n",
    "\t\t\t\n",
    "\t\t\tposition, margin, fees = self.backtest(pair_df, stock1, stock2, beta, initial_capital, best_entry_z_threshold, best_exit_z_threshold)\n",
    "\n",
    "\t\t\tself._log(f'[{self.symbol_helper(stock1)} {self.symbol_helper(stock2)}] Entry z threshold: {best_entry_z_threshold:.3f} Exit z threshold: {best_exit_z_threshold:.3f} Cum PnL: {(margin[-1]-margin[0]):.3f}')\n",
    "\t\t\tself.plot_pair_backtest(pair_df, training_pair_df, stock1, stock2, beta, best_entry_z_threshold, best_exit_z_threshold, position, fees, margin)\n",
    "\n",
    "\t\t\ttest_backtest_results[stock1+'-'+stock2] = [position, margin, fees]\n",
    "\n",
    "\t\treturn test_backtest_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "\tfrom datapipeline import DataPipeline\n",
    "\tfrom clusterpipeline import ClusterPipeline\n",
    "\tfrom portfoliopipeline import PortfolioPipeline\n",
    "\tfrom backtestpipeline import BacktestPipeline\n",
    "except:\n",
    "\tpass\n",
    "\n",
    "sectors_dict = {\n",
    "\t'final': ['DBCN UX9SXI5CAPNP', 'HEWG VNTW0AC8LAHX', 'GSJY W8L8B8ZCNXB9', 'ITF S96RH23DIAUD', 'EFO UD63CSAA26P1', 'UPV UM61FJMT8EHX', 'EFU TX34HT712KBP',  'EPV UDJVM3EN4QXX', 'DGZ U0K69ONGSDPH', 'DZZ U0J6TLAAPMJP'] #, 'GLL U85WJOCE24BP']\n",
    "}\n",
    "\n",
    "total_pairs_found = 0\n",
    "total_pairs_validated = 0\n",
    "final_results = pd.DataFrame({ 'Stock1': [], 'Stock2': [], 'Beta': [], 'p': [], 'H': [], 'Half-life': [], 'Avg zero cross period': [], 'Cluster': [], 'Best entry z threshold': [], 'Best exit z threshold': [], 'Validation Fees': [], 'Validation PnL': [], 'Sector': [] })\n",
    "\n",
    "for sector in sectors_dict:\n",
    "\tdisplay(f'Doing {sector} sector now')\n",
    "\n",
    "\tdata_pipe = DataPipeline(sectors_dict[sector], (2018, 1, 1), (2020, 1, 1), (2022, 1, 1), (2023, 1, 1))\n",
    "\ttraining_df, validation_df, testing_df, training_and_validation_df = data_pipe.preprocess_and_split_data()\n",
    "\n",
    "\tcluster_pipe = ClusterPipeline() \n",
    "\tclusters = [training_df.columns] if training_df.shape[1] < 15 else cluster_pipe.find_clusters(training_df)\n",
    "\n",
    "\tportfolio_pipe = PortfolioPipeline()\n",
    "\tbacktest_pipe = BacktestPipeline()\n",
    "\n",
    "\t# get pairs for validation test\n",
    "\tvalidation_pairs = portfolio_pipe.find_pairs_from_clusters(training_df, clusters)\n",
    "\tif validation_pairs is None or validation_pairs.shape[0] == 0:\n",
    "\t\tdisplay(f'Found nothing in {sector} sector')\n",
    "\t\tcontinue\n",
    "\n",
    "\ttotal_pairs_found += validation_pairs.shape[0]\n",
    "\n",
    "\tinitial_capital = 30000\n",
    "\t# initial_capital_per_pair = initial_capital // validation_pairs.shape[0]\n",
    "\n",
    "\t# validation backtest\n",
    "\tvalidation_backtest_results = backtest_pipe.validation_backtest(training_df, validation_df, validation_pairs, initial_capital=5000)\n",
    "\tsorted_validation_backtest_results = sorted(validation_backtest_results, key=lambda x: x[-1][-1]-x[-1][0], reverse=True)\n",
    "\tbacktest_pipe.plot_validation_backtest_results(sorted_validation_backtest_results)\n",
    "\n",
    "\tfiltered_validation_pairs = portfolio_pipe.filter_positive_pnl_pairs(validation_pairs, sorted_validation_backtest_results, min_validation_return_threshold=0.1)\n",
    "\tif filtered_validation_pairs.shape[0] == 0:\n",
    "\t\tdisplay(f'No positive validated pairs in {sector} sector')\n",
    "\t\tcontinue\n",
    "\n",
    "\ttotal_pairs_validated += filtered_validation_pairs.shape[0]\n",
    "\n",
    "\t# get final test pairs\n",
    "\ttest_pairs = portfolio_pipe.revalidate_pairs(training_and_validation_df, filtered_validation_pairs, sector)\n",
    "\n",
    "\t# test backtest\n",
    "\ttest_backtest_results = backtest_pipe.test_backtest(training_and_validation_df, testing_df, test_pairs, initial_capital=5000)\n",
    "\n",
    "\n",
    "\tfinal_results = pd.concat([final_results, test_pairs], ignore_index=True)\n",
    "\n",
    "display(final_results)\n",
    "display(f'Final result for all sectors: Total pairs validated / total pairs found = {total_pairs_validated}/{total_pairs_found} = {total_pairs_validated/total_pairs_found*100:.2f}% pairs ')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
